{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with custom ollama wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Search Response: A knowledge graph is a structured representation of information that models real-world entities and their interrelationships. It consists of nodes (entities) and edges (relationships) to create a network that encodes data in a way that allows for semantic queries and reasoning.\n",
      "\n",
      "Key characteristics of knowledge graphs include:\n",
      "\n",
      "1. **Entities**: These are the basic units or objects, such as people, places, things, or concepts.\n",
      "2. **Relationships**: These define how entities are connected, indicating various types of interactions or associations between them.\n",
      "3. **Attributes/Properties**: Additional information about entities and relationships can be stored to enrich the graph.\n",
      "\n",
      "Knowledge graphs enable sophisticated data integration, retrieval, and analysis by allowing machines to understand context, semantics, and concepts in a manner similar to human understanding. They are often powered by technologies like RDF (Resource Description Framework), SPARQL (a query language for databases), and ontologies which provide formal structures for categorizing and linking information.\n",
      "\n",
      "Applications of knowledge graphs span various domains such as:\n",
      "\n",
      "- **Search Engines**: Enhancing search results with contextually relevant information.\n",
      "- **Personal Assistants**: Providing more accurate and meaningful responses to user queries.\n",
      "- **Recommendation Systems**: Improving suggestions by understanding user preferences and connections between different types of content.\n",
      "- **Enterprise Solutions**: Facilitating better decision-making through unified views of disparate data sources.\n",
      "\n",
      "By organizing information in a graph structure, knowledge graphs facilitate easier access to interconnected data points, supporting advanced analytics, machine learning, and artificial intelligence applications.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import os\n",
    "# Force bypass of proxy\n",
    "os.environ[\"no_proxy\"] = \"192.168.13.13\"\n",
    "# Define multiple Ollama clients for different machines\n",
    "global_search_client = ollama.Client(host='http://192.168.13.13:11434')  # Machine 1 (GraphRAG Global Search)\n",
    "# local_search_client = ollama.Client(host='http://192.168.1.101:11434')  # Machine 2 (GraphRAG Local Search)\n",
    "\n",
    "# Use them accordingly\n",
    "response_global = global_search_client.chat(model='phi4:latest', messages=[{'role': 'user', 'content': 'What is knowledge graph?'}])\n",
    "# response_local = local_search_client.chat(model='graphrag-local', messages=[{'role': 'user', 'content': 'Find similar entities to \"GraphRAG\".'}])\n",
    "\n",
    "print(\"Global Search Response:\", response_global['message']['content'])\n",
    "# print(\"Local Search Response:\", response_local['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we understood how to configure ollama instances with custom client ip. Next we need to integrate this into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Search Response: A knowledge graph is a structured representation of information that illustrates the relationships between entities (such as people, places, things) and the concepts they represent. It organizes data in a way that makes it easier to understand how different pieces of information are interconnected. Here's a breakdown of its key components:\n",
      "\n",
      "1. **Entities**: These are the primary objects or subjects within the graph. Each entity is typically represented by a node.\n",
      "\n",
      "2. **Attributes**: Entities can have attributes or properties that provide additional details about them, similar to fields in a database.\n",
      "\n",
      "3. **Relationships/Edges**: These are connections between entities that describe how they relate to each other. They help illustrate the context and interactions between nodes.\n",
      "\n",
      "4. **Schema/Ontology**: This defines the types of entities, relationships, and attributes included in the knowledge graph, providing structure and meaning.\n",
      "\n",
      "5. **Data Sources**: Knowledge graphs aggregate information from various sources such as databases, web pages, APIs, or even user-generated content to ensure richness and accuracy.\n",
      "\n",
      "Knowledge graphs are widely used in applications like search engines (e.g., Google's Knowledge Graph), recommendation systems, natural language processing, data integration, and more. They enable machines to understand context and semantics better, improving the ability to retrieve, infer, and generate insights from large datasets.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "import ollama\n",
    "from pydantic import Field, ConfigDict\n",
    "import os\n",
    "\n",
    "class OllamaClient:\n",
    "    def __init__(self, instances):\n",
    "        \"\"\"\n",
    "        Initializes multiple Ollama clients for different machines.\n",
    "\n",
    "        Args:\n",
    "        - instances (dict): A dictionary mapping models to their respective Ollama server URLs.\n",
    "                            Example: {\"graphrag-global\": \"http://192.168.13.13:11434\"}\n",
    "        \"\"\"\n",
    "        self.clients = {model: ollama.Client(host=host) for model, host in instances.items()}\n",
    "        \n",
    "        # Ensure proxy is bypassed for local network\n",
    "        os.environ[\"NO_PROXY\"] = \",\".join(instances.values())\n",
    "\n",
    "    def __call__(self, prompt,model=\"phi4:latest\",):\n",
    "        \"\"\"\n",
    "        Sends a chat request to the appropriate Ollama instance based on the model.\n",
    "\n",
    "        Args:\n",
    "        - model (str): The name of the model (e.g., 'graphrag-global').\n",
    "        - prompt (str): The user query.\n",
    "\n",
    "        Returns:\n",
    "        - str: The model's response.\n",
    "        \"\"\"\n",
    "        if model not in self.clients:\n",
    "            raise ValueError(f\"No Ollama instance configured for model '{model}'\")\n",
    "\n",
    "        response = self.clients[model].chat(\n",
    "            model=model, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "    \n",
    "    def list_models(self, model):\n",
    "        \"\"\"\n",
    "        Lists available models from a specific Ollama instance.\n",
    "\n",
    "        Args:\n",
    "        - model (str): The model associated with a specific Ollama instance.\n",
    "\n",
    "        Returns:\n",
    "        - list: A list of available models.\n",
    "        \"\"\"\n",
    "        if model not in self.clients:\n",
    "            raise ValueError(f\"No Ollama instance configured for model '{model}'\")\n",
    "\n",
    "        return self.clients[model].list()\n",
    "\n",
    "\n",
    "# Force bypass of proxy\n",
    "os.environ[\"no_proxy\"] = \"192.168.13.13\"\n",
    "os.environ[\"HTTP_PROXY\"] = \"\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"\"\n",
    "# Define Ollama instances\n",
    "global_search_llm = OllamaClient({\"phi4:latest\": \"http://192.168.13.13:11434\"})\n",
    "\n",
    "# Test the instances\n",
    "response_global = global_search_llm(prompt=\"What is a knowledge graph?\")\n",
    "\n",
    "\n",
    "print(\"Global Search Response:\", response_global)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to make the class a langchain runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Search Response: A knowledge graph is a data structure that organizes and represents information in a way that highlights the relationships between different entities. It consists of nodes (entities) and edges (relationships or connections) to form a network that can be used for various applications, such as enhancing search engine capabilities, improving recommendation systems, or powering artificial intelligence models.\n",
      "\n",
      "Key features of knowledge graphs include:\n",
      "\n",
      "1. **Entities**: These are objects, concepts, people, places, or any other significant items in the data domain being represented. They serve as nodes within the graph.\n",
      "\n",
      "2. **Relationships**: Edges connect entities and denote the relationships between them. These can describe various types of associations like \"is a part of,\" \"created by,\" \"located in,\" etc.\n",
      "\n",
      "3. **Attributes/Properties**: Entities often have associated properties or attributes, such as a person's birthdate or a locationâ€™s coordinates.\n",
      "\n",
      "4. **Interoperability and Scalability**: Knowledge graphs are designed to integrate data from various sources, making them scalable and adaptable for evolving datasets.\n",
      "\n",
      "5. **Semantic Understanding**: They support semantic queries that go beyond keyword matching by understanding the context and meaning of the entities and their relationships.\n",
      "\n",
      "Applications of knowledge graphs include:\n",
      "\n",
      "- **Enhanced Search**: Improving search engine results by understanding user intent and providing more relevant information.\n",
      "  \n",
      "- **Data Integration**: Combining data from disparate sources into a cohesive framework for better insights.\n",
      "\n",
      "- **Recommendation Systems**: Providing personalized suggestions based on the relationships between items and users.\n",
      "\n",
      "- **AI and Machine Learning**: Serving as a knowledge base that AI systems can leverage to improve decision-making processes.\n",
      "\n",
      "Well-known examples of organizations using knowledge graphs include Google's Knowledge Graph, which enhances its search engine capabilities by providing richer information snippets in response to user queries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import os\n",
    "from langchain.schema.runnable import RunnableSerializable\n",
    "from pydantic import Field\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "import ollama\n",
    "import os\n",
    "from langchain.schema.runnable import RunnableSerializable\n",
    "from pydantic import Field\n",
    "\n",
    "class MultiOllamaClient(RunnableSerializable):\n",
    "    clients: dict = Field(default_factory=dict, exclude=True)  # Exclude from Pydantic\n",
    "    instances: dict = Field(default_factory=dict, exclude=True)  # Exclude from Pydantic\n",
    "    temperature: float = Field(default=0.2, exclude=True)  # Exclude from Pydantic\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes multiple Ollama clients for different machines.\n",
    "\n",
    "        Args:\n",
    "        - instances (dict): A dictionary mapping models to their respective Ollama server URLs.\n",
    "                            Example: {\"graphrag-global\": \"http://192.168.13.13:11434\"}\n",
    "        - temperature (float): The temperature setting for the LLM responses.\n",
    "        \"\"\"\n",
    "        instances = kwargs.get(\"instances\", None)\n",
    "        if instances is None:\n",
    "            raise ValueError(\"You must provide an 'instances' dictionary.\")\n",
    "\n",
    "        object.__setattr__(self, \"clients\", {model: ollama.Client(host=host) for model, host in instances.items()})\n",
    "        object.__setattr__(self, \"temperature\", kwargs.get(\"temperature\", 0.2))  # âœ… Fixed Assignment\n",
    "\n",
    "    def __call__(self, input_data):\n",
    "        \"\"\"\n",
    "        Handles LangChain-style input.\n",
    "\n",
    "        Args:\n",
    "        - input_data (dict): Expected format {\"model\": \"model_name\", \"prompt\": \"query\"}\n",
    "\n",
    "        Returns:\n",
    "        - str: The model's response.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data, str):\n",
    "            raise ValueError(\"Expected dictionary input with 'model' and 'prompt' keys.\")\n",
    "\n",
    "        model = input_data.get(\"model\", \"phi4:latest\")\n",
    "        prompt = input_data.get(\"prompt\")\n",
    "\n",
    "        if model not in self.clients:\n",
    "            raise ValueError(f\"No Ollama instance configured for model '{model}'\")\n",
    "\n",
    "        response = self.clients[model].chat(\n",
    "            model=model, messages=[{\"role\": \"user\", \"content\": prompt}], options={\"temperature\": self.temperature}\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "    \n",
    "    def invoke(self, input_data):\n",
    "        \"\"\"\n",
    "        Handles LangChain-style input.\n",
    "\n",
    "        Args:\n",
    "        - input_data (dict): Expected format {\"model\": \"model_name\", \"prompt\": \"query\"}\n",
    "\n",
    "        Returns:\n",
    "        - str: The model's response.\n",
    "        \"\"\"\n",
    "        return self.__call__(input_data)  # âœ… Now calls __call__()\n",
    "\n",
    "    def list_models(self, model):\n",
    "        \"\"\"\n",
    "        Lists available models from a specific Ollama instance.\n",
    "\n",
    "        Args:\n",
    "        - model (str): The model associated with a specific Ollama instance.\n",
    "\n",
    "        Returns:\n",
    "        - list: A list of available models.\n",
    "        \"\"\"\n",
    "        if model not in self.clients:\n",
    "            raise ValueError(f\"No Ollama instance configured for model '{model}'\")\n",
    "\n",
    "        return self.clients[model].list()\n",
    "\n",
    "\n",
    "\n",
    "# Force bypass of proxy\n",
    "# os.environ[\"no_proxy\"] = \"192.168.13.13\"\n",
    "# Instead just set following through terminal\n",
    "# conda config --set proxy_servers.http \"\" \n",
    "# conda config --set proxy_servers.https \"\"\n",
    "\n",
    "# Define Ollama instances dynamically\n",
    "ollama_runnable = MultiOllamaClient(instances={\"phi4:latest\": \"http://192.168.13.13:11434\"},temperature=0.9)\n",
    "\n",
    "# Use inside a Runnable Chain\n",
    "chain = RunnableLambda(ollama_runnable)\n",
    "\n",
    "# Invoke the chain\n",
    "response_global = chain.invoke({\"prompt\": \"What is a knowledge graph?\"})\n",
    "\n",
    "\n",
    "print(\"Global Search Response:\", response_global)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
